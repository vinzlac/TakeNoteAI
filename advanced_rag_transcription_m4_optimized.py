#!/usr/bin/env python3
# Version optimis√©e pour Mac M4
# G√©n√©r√©e automatiquement par optimize_rag_for_m4.py

import warnings
import torch
import os

# Optimisations M4 - D√âBUT
if torch.backends.mps.is_available():
    torch.set_num_threads(14)
    os.environ['OMP_NUM_THREADS'] = '14'
    os.environ['MKL_NUM_THREADS'] = '14'
    os.environ['NUMEXPR_NUM_THREADS'] = '14'
    print("üöÄ Optimisations Mac M4 activ√©es")
else:
    print("‚ö†Ô∏è  MPS non disponible - Utilisation CPU uniquement")
# Optimisations M4 - FIN

#!/usr/bin/env python3
"""
Script avanc√© de transcription avec RAG et extraction de mots-cl√©s m√©tiers
Combine SpeechBrain, KeyBERT, Sentence Transformers et ChromaDB
"""

import os
import sys
import argparse
import json
import warnings
import torch
import os

# Optimisations M4
if torch.backends.mps.is_available():
    torch.set_num_threads(14)
    os.environ['OMP_NUM_THREADS'] = '14'
    os.environ['MKL_NUM_THREADS'] = '14'
    os.environ['NUMEXPR_NUM_THREADS'] = '14'
    print("üöÄ Optimisations M4 activ√©es")

from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import numpy as np

# Supprimer les avertissements d√®s le d√©but
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=PendingDeprecationWarning)

# Imports pour la transcription
import whisper  # Import Whisper en premier
try:
    import torch
    import torchaudio
    from speechbrain.inference import EncoderDecoderASR
    SPEECHBRAIN_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  SpeechBrain non disponible, utilisation de Whisper en fallback")
    SPEECHBRAIN_AVAILABLE = False

# Imports pour RAG et embeddings
try:
    from sentence_transformers import SentenceTransformer
    from keybert import KeyBERT
    import chromadb
    from chromadb.config import Settings
    RAG_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è  Composants RAG non disponibles: {e}")
    print("üí° Installez avec: pip install sentence-transformers keybert chromadb")
    RAG_AVAILABLE = False

# Imports pour le traitement de texte
try:
    import spacy
    from spacy.lang.fr.stop_words import STOP_WORDS
    SPACY_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  spaCy non disponible, utilisation de stop words basiques")
    SPACY_AVAILABLE = False

class AdvancedRAGTranscription:
    """Classe pour transcription avanc√©e avec RAG et extraction de mots-cl√©s m√©tiers."""
    
    def _get_optimal_device(self):
        """D√©tecte le device optimal pour M4."""
        if torch.backends.mps.is_available():
            print("‚úÖ GPU M4 d√©tect√© via MPS")
            return "mps"
        elif torch.cuda.is_available():
            print("‚úÖ GPU CUDA d√©tect√©")
            return "cuda"
        else:
            print("‚ö†Ô∏è  Utilisation CPU uniquement")
            return "cpu"
    
    def __init__(self, 
                 transcription_model="speechbrain/asr-crdnn-commonvoice-fr",
                 embedding_model="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                 device=None):
        """
        Initialise les mod√®les pour transcription, embeddings et extraction de mots-cl√©s.
        
        Args:
            transcription_model (str): Mod√®le de transcription SpeechBrain
            embedding_model (str): Mod√®le d'embeddings Sentence Transformers
            device (str): Device √† utiliser
        """
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        print(f"üîß Initialisation des mod√®les avanc√©s...")
        print(f"   Device: {self.device}")
        
        # Initialiser le mod√®le de transcription
        self._init_transcription_model(transcription_model)
        
        # Initialiser les composants RAG si disponibles
        if RAG_AVAILABLE:
            self._init_rag_components(embedding_model)
        else:
            print("‚ö†Ô∏è  Mode d√©grad√©: RAG non disponible")
    
    def _init_transcription_model(self, model_name: str):
        """Initialise le mod√®le de transcription."""
        print("üîÑ Chargement du mod√®le de transcription...")
        
        if SPEECHBRAIN_AVAILABLE and "whisper" not in model_name.lower():
            try:
                # Essayer SpeechBrain avec gestion d'erreur am√©lior√©e
                from speechbrain.pretrained import EncoderDecoderASR
                self.asr_model = EncoderDecoderASR.from_hparams(
                    source=model_name,
                    savedir=f"pretrained_models/{model_name.split('/')[-1]}"
                )
                self.transcription_method = "speechbrain"
                print(f"‚úÖ Mod√®le SpeechBrain charg√©: {model_name}")
            except Exception as e:
                error_msg = str(e).lower()
                if "401" in error_msg or "authentication" in error_msg or "token" in error_msg:
                    print(f"‚ö†Ô∏è  Erreur d'authentification SpeechBrain: Token Hugging Face requis")
                    print("üí° Solution: huggingface-cli login")
                elif "not found" in error_msg:
                    print(f"‚ö†Ô∏è  Mod√®le SpeechBrain non trouv√©: {model_name}")
                else:
                    print(f"‚ö†Ô∏è  Erreur SpeechBrain: {e}")
                print("üîÑ Basculement vers Whisper...")
                self.asr_model = whisper.load_model("base", device=self.device)
            
            # Optimisations M4
            if self.device == "mps":
                print("üöÄ Optimisations M4 appliqu√©es au mod√®le Whisper")
                # Mixed precision pour MPS
                if hasattr(self.asr_model, 'half'):
                    self.asr_model.half()
                self.transcription_method = "whisper"
        else:
            # Utiliser directement Whisper
            if "whisper" in model_name.lower():
                model_size = model_name.split("-")[-1] if "-" in model_name else "base"
                self.asr_model = whisper.load_model(model_size, device=self.device)
            else:
                self.asr_model = whisper.load_model("base", device=self.device)
            
            # Optimisations M4
            if self.device == "mps":
                print("üöÄ Optimisations M4 appliqu√©es au mod√®le Whisper")
                # Mixed precision pour MPS
                if hasattr(self.asr_model, 'half'):
                    self.asr_model.half()
            self.transcription_method = "whisper"
    
    def _init_rag_components(self, embedding_model: str):
        """Initialise les composants RAG."""
        print("üîÑ Initialisation des composants RAG...")
        
        # Mod√®le d'embeddings
        print("   - Chargement du mod√®le d'embeddings...")
        self.embedding_model = SentenceTransformer(embedding_model, device=self.device)
        
        # Extracteur de mots-cl√©s
        print("   - Initialisation de KeyBERT...")
        self.keybert_model = KeyBERT(model=self.embedding_model)
        
        # Base de donn√©es vectorielle
        print("   - Configuration de ChromaDB...")
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        
        # Collection pour les documents
        try:
            self.collection = self.chroma_client.get_collection("transcriptions")
        except:
            self.collection = self.chroma_client.create_collection("transcriptions")
        
        # Mod√®le spaCy pour le traitement de texte
        if SPACY_AVAILABLE:
            try:
                self.nlp = spacy.load("fr_core_news_sm")
            except OSError:
                print("   ‚ö†Ô∏è  Mod√®le spaCy fran√ßais non trouv√©, installation...")
                os.system("python -m spacy download fr_core_news_sm")
                self.nlp = spacy.load("fr_core_news_sm")
        
        print("‚úÖ Composants RAG initialis√©s")
    
    def transcribe_audio(self, audio_path: str) -> Dict:
        """
        Transcrit l'audio avec le mod√®le choisi.
        
        Args:
            audio_path (str): Chemin vers le fichier audio
            
        Returns:
            Dict: R√©sultat de la transcription
        """
        print(f"üé§ Transcription avec {self.transcription_method}...")
        
        if self.transcription_method == "speechbrain":
            # Transcription avec API SpeechBrain moderne et correcte
            try:
                # M√©thode SpeechBrain moderne - utiliser transcribe_file
                text = self.asr_model.transcribe_file(audio_path)
                
                # Formatage du r√©sultat
                result = {
                    "text": text,
                    "segments": [{"start": 0, "end": len(text)/10, "text": text}],
                    "language": "fr",
                    "method": "speechbrain"
                }
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur SpeechBrain lors de la transcription: {e}")
                print("üîÑ Basculement vers Whisper...")
                # Fallback vers Whisper - charger un nouveau mod√®le Whisper
                import whisper
                whisper_model = whisper.load_model("base", device=self.device)
            
            # Optimisations M4
            if self.device == "mps":
                print("üöÄ Optimisations M4 appliqu√©es au mod√®le Whisper")
                # Mixed precision pour MPS
                if hasattr(self.asr_model, 'half'):
                    self.asr_model.half()
                result = whisper_model.transcribe(audio_path, verbose=True)
                result["method"] = "whisper"
        else:
            # Whisper fallback
            result = self.asr_model.transcribe(audio_path, verbose=True)
            result["method"] = "whisper"
        
        return result
    
    def extract_business_keywords(self, text: str, top_k: int = 10) -> List[Tuple[str, float]]:
        """
        Extrait les mots-cl√©s m√©tiers du texte.
        
        Args:
            text (str): Texte √† analyser
            top_k (int): Nombre de mots-cl√©s √† extraire
            
        Returns:
            List[Tuple[str, float]]: Mots-cl√©s avec scores
        """
        if not RAG_AVAILABLE:
            return []
        
        print("üîç Extraction des mots-cl√©s m√©tiers...")
        
        # Extraction avec KeyBERT
        keywords = self.keybert_model.extract_keywords(
            text, 
            keyphrase_ngram_range=(1, 3),
            stop_words='french' if SPACY_AVAILABLE else None,
            top_n=top_k,
            use_mmr=True,
            diversity=0.5
        )
        
        # Filtrage des mots-cl√©s m√©tiers
        business_keywords = self._filter_business_keywords(keywords, text)
        
        print(f"‚úÖ {len(business_keywords)} mots-cl√©s m√©tiers extraits")
        return business_keywords
    
    def _filter_business_keywords(self, keywords: List[Tuple[str, float]], text: str) -> List[Tuple[str, float]]:
        """
        Filtre les mots-cl√©s pour ne garder que ceux li√©s au m√©tier.
        
        Args:
            keywords (List[Tuple[str, float]]): Mots-cl√©s extraits
            text (str): Texte original
            
        Returns:
            List[Tuple[str, float]]: Mots-cl√©s m√©tiers filtr√©s
        """
        # Mots-cl√©s m√©tiers typiques (√† adapter selon le domaine)
        business_indicators = [
            "projet", "√©quipe", "d√©veloppement", "architecture", "code", "review",
            "maintenance", "go-live", "application", "syst√®me", "technologie",
            "processus", "m√©thodologie", "qualit√©", "performance", "s√©curit√©",
            "int√©gration", "d√©ploiement", "test", "validation", "documentation",
            "formation", "support", "monitoring", "backup", "migration"
        ]
        
        filtered_keywords = []
        text_lower = text.lower()
        
        for keyword, score in keywords:
            keyword_lower = keyword.lower()
            
            # V√©rifier si le mot-cl√© contient des indicateurs m√©tiers
            is_business = any(indicator in keyword_lower for indicator in business_indicators)
            
            # V√©rifier la fr√©quence dans le texte
            frequency = text_lower.count(keyword_lower)
            
            # Score combin√©: score KeyBERT + fr√©quence + indicateur m√©tier
            combined_score = score + (frequency * 0.1) + (0.2 if is_business else 0)
            
            if combined_score > 0.3:  # Seuil minimum
                filtered_keywords.append((keyword, combined_score))
        
        # Trier par score d√©croissant
        filtered_keywords.sort(key=lambda x: x[1], reverse=True)
        
        return filtered_keywords[:10]  # Top 10
    
    def create_embeddings(self, text: str) -> np.ndarray:
        """
        Cr√©e les embeddings vectoriels du texte.
        
        Args:
            text (str): Texte √† vectoriser
            
        Returns:
            np.ndarray: Embeddings vectoriels
        """
        if not RAG_AVAILABLE:
            return np.array([])
        
        print("üß† G√©n√©ration des embeddings...")
        embeddings = self.embedding_model.encode(text)
        return embeddings
    
    def store_in_vector_db(self, text: str, metadata: Dict, embeddings: np.ndarray):
        """
        Stocke le texte et ses embeddings dans la base vectorielle.
        
        Args:
            text (str): Texte √† stocker
            metadata (Dict): M√©tadonn√©es
            embeddings (np.ndarray): Embeddings vectoriels
        """
        if not RAG_AVAILABLE:
            return
        
        print("üíæ Stockage dans la base vectorielle...")
        
        # ID unique bas√© sur le timestamp
        doc_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # Ajouter √† la collection
        self.collection.add(
            documents=[text],
            embeddings=[embeddings.tolist()],
            metadatas=[metadata],
            ids=[doc_id]
        )
        
        print(f"‚úÖ Document stock√© avec ID: {doc_id}")
    
    def search_similar_documents(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        Recherche des documents similaires dans la base vectorielle.
        
        Args:
            query (str): Requ√™te de recherche
            top_k (int): Nombre de r√©sultats √† retourner
            
        Returns:
            List[Dict]: Documents similaires
        """
        if not RAG_AVAILABLE:
            return []
        
        print(f"üîç Recherche de documents similaires: '{query}'")
        
        # Embeddings de la requ√™te
        query_embeddings = self.embedding_model.encode(query)
        
        # Recherche dans la base
        results = self.collection.query(
            query_embeddings=[query_embeddings.tolist()],
            n_results=top_k
        )
        
        # Formatage des r√©sultats
        similar_docs = []
        for i in range(len(results['documents'][0])):
            similar_docs.append({
                "text": results['documents'][0][i],
                "metadata": results['metadatas'][0][i],
                "distance": results['distances'][0][i],
                "id": results['ids'][0][i]
            })
        
        print(f"‚úÖ {len(similar_docs)} documents similaires trouv√©s")
        return similar_docs
    
    def process_audio_complete(self, audio_path: str, output_path: str = None) -> Dict:
        """
        Traite un fichier audio complet : transcription + RAG + mots-cl√©s.
        
        Args:
            audio_path (str): Chemin vers le fichier audio
            output_path (str): Chemin de sortie
            
        Returns:
            Dict: R√©sultats complets
        """
        audio_path = Path(audio_path)
        
        if not audio_path.exists():
            raise FileNotFoundError(f"Le fichier {audio_path} n'existe pas")
        
        # G√©n√©rer le nom de sortie
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = audio_path.parent / f"{audio_path.stem}_advanced_rag_{timestamp}.json"
        else:
            output_path = Path(output_path)
        
        print(f"üöÄ Traitement avanc√©: {audio_path.name}")
        print(f"   Taille: {audio_path.stat().st_size / 1024 / 1024:.2f} MB")
        
        try:
            # 1. Transcription
            transcription_result = self.transcribe_audio(str(audio_path))
            full_text = transcription_result["text"]
            
            # 2. Extraction de mots-cl√©s m√©tiers
            business_keywords = self.extract_business_keywords(full_text)
            
            # 3. G√©n√©ration d'embeddings
            embeddings = self.create_embeddings(full_text)
            
            # 4. M√©tadonn√©es
            metadata = {
                "filename": audio_path.name,
                "size_mb": round(audio_path.stat().st_size / 1024 / 1024, 2),
                "transcription_method": self.transcription_method,
                "language": transcription_result.get("language", "unknown"),
                "duration": round(transcription_result.get("duration", 0), 2),
                "timestamp": datetime.now().isoformat(),
                "business_keywords_count": len(business_keywords)
            }
            
            # 5. Stockage dans la base vectorielle
            if RAG_AVAILABLE and len(embeddings) > 0:
                self.store_in_vector_db(full_text, metadata, embeddings)
            
            # 6. R√©sultats complets
            results = {
                "transcription": transcription_result,
                "business_keywords": business_keywords,
                "metadata": metadata,
                "embeddings_available": RAG_AVAILABLE and len(embeddings) > 0,
                "vector_db_stored": RAG_AVAILABLE
            }
            
            # 7. Sauvegarde
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            
            # 8. Statistiques
            print(f"\n‚úÖ Traitement avanc√© termin√©!")
            print(f"üìä Statistiques:")
            print(f"   - M√©thode de transcription: {self.transcription_method}")
            print(f"   - Longueur du texte: {len(full_text)} caract√®res")
            print(f"   - Mots-cl√©s m√©tiers: {len(business_keywords)}")
            print(f"   - Embeddings g√©n√©r√©s: {'Oui' if RAG_AVAILABLE else 'Non'}")
            print(f"   - Stock√© en base vectorielle: {'Oui' if RAG_AVAILABLE else 'Non'}")
            print(f"   - Fichier de sortie: {output_path}")
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erreur lors du traitement: {e}")
            raise


def main():
    """Fonction principale."""
    parser = argparse.ArgumentParser(
        description="Transcription avanc√©e avec RAG et extraction de mots-cl√©s m√©tiers",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  %(prog)s audio.mp3                           # Traitement complet
  %(prog)s audio.mp3 -o results.json          # Sortie personnalis√©e
  %(prog)s audio.mp3 --search "architecture"  # Recherche dans la base
        """
    )
    
    parser.add_argument("input", help="Fichier audio d'entr√©e")
    parser.add_argument("-o", "--output", help="Fichier de sortie JSON")
    parser.add_argument("--search", help="Rechercher des documents similaires")
    parser.add_argument("--transcription-model", 
                       default="speechbrain/asr-crdnn-commonvoice-fr",
                       help="Mod√®le de transcription SpeechBrain")
    parser.add_argument("--embedding-model",
                       default="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                       help="Mod√®le d'embeddings")
    parser.add_argument("--device", choices=["cpu", "cuda", "mps"],
                       help="Device √† utiliser")
    
    args = parser.parse_args()
    
    try:
        # Initialiser le processeur
        processor = AdvancedRAGTranscription(
            transcription_model=args.transcription_model,
            embedding_model=args.embedding_model,
            device=args.device
        )
        
        if args.search:
            # Recherche dans la base existante
            results = processor.search_similar_documents(args.search)
            print(f"\nüîç R√©sultats de recherche pour '{args.search}':")
            for i, doc in enumerate(results, 1):
                print(f"{i}. Distance: {doc['distance']:.3f}")
                print(f"   Texte: {doc['text'][:100]}...")
                print(f"   M√©tadonn√©es: {doc['metadata']}")
                print()
        else:
            # Traitement complet
            results = processor.process_audio_complete(args.input, args.output)
            
            print(f"\nüéâ Succ√®s! R√©sultats sauvegard√©s: {args.output or 'auto-g√©n√©r√©'}")
            
            # Afficher les mots-cl√©s m√©tiers
            if results.get("business_keywords"):
                print(f"\nüîë Mots-cl√©s m√©tiers d√©tect√©s:")
                for keyword, score in results["business_keywords"][:5]:
                    print(f"   - {keyword} (score: {score:.3f})")
        
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Traitement interrompu par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\nüí• Erreur fatale: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()

