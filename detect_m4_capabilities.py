#!/usr/bin/env python3
"""
Script de d√©tection des capacit√©s Mac M4
"""

import torch
import platform
import psutil
import subprocess
import sys

def detect_m4_capabilities():
    """D√©tecte les capacit√©s du Mac M4."""
    print("üîç D√©tection des capacit√©s Mac M4...")
    print("=" * 50)
    
    # Informations syst√®me
    print("üíª Informations syst√®me:")
    print(f"   - Syst√®me: {platform.system()} {platform.release()}")
    print(f"   - Architecture: {platform.machine()}")
    print(f"   - Version Python: {sys.version}")
    
    # Capacit√©s CPU
    print(f"\nüß† Capacit√©s CPU:")
    print(f"   - C≈ìurs physiques: {psutil.cpu_count(logical=False)}")
    print(f"   - C≈ìurs logiques: {psutil.cpu_count(logical=True)}")
    print(f"   - Fr√©quence: {psutil.cpu_freq().current:.0f} MHz")
    
    # M√©moire
    memory = psutil.virtual_memory()
    print(f"\nüíæ M√©moire:")
    print(f"   - Total: {memory.total / 1024**3:.1f} GB")
    print(f"   - Disponible: {memory.available / 1024**3:.1f} GB")
    print(f"   - Utilis√©e: {memory.percent}%")
    
    # Capacit√©s PyTorch
    print(f"\nüî• Capacit√©s PyTorch:")
    print(f"   - Version PyTorch: {torch.__version__}")
    print(f"   - CUDA disponible: {torch.cuda.is_available()}")
    print(f"   - MPS disponible: {torch.backends.mps.is_available()}")
    
    if torch.backends.mps.is_available():
        print("   ‚úÖ GPU M4 d√©tect√© via MPS")
        try:
            # Tester MPS
            device = torch.device("mps")
            x = torch.randn(10, 10).to(device)
            y = torch.randn(10, 10).to(device)
            z = torch.mm(x, y)
            print("   ‚úÖ MPS fonctionnel")
        except Exception as e:
            print(f"   ‚ùå Erreur MPS: {e}")
    else:
        print("   ‚ùå MPS non disponible")
    
    # D√©tection du Neural Engine
    print(f"\nüß† Neural Engine:")
    try:
        # V√©rifier Core ML
        import coremltools as ct
        print("   ‚úÖ Core ML disponible")
        print(f"   - Version: {ct.__version__}")
    except ImportError:
        print("   ‚ùå Core ML non install√©")
        print("   üí° Installez avec: pip install coremltools")
    
    # D√©tection Metal
    print(f"\nüéÆ Capacit√©s Metal:")
    try:
        result = subprocess.run(['system_profiler', 'SPDisplaysDataType'], 
                              capture_output=True, text=True)
        if 'Metal' in result.stdout:
            print("   ‚úÖ Metal disponible")
        else:
            print("   ‚ùå Metal non d√©tect√©")
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Impossible de v√©rifier Metal: {e}")
    
    # Optimisations recommand√©es
    print(f"\nüöÄ Optimisations recommand√©es:")
    
    if torch.backends.mps.is_available():
        print("   ‚úÖ Utiliser MPS pour l'acc√©l√©ration GPU")
        print("   ‚úÖ Activer mixed precision")
        print("   ‚úÖ Utiliser tous les c≈ìurs CPU")
        recommended_device = "mps"
    elif torch.cuda.is_available():
        print("   ‚úÖ Utiliser CUDA pour l'acc√©l√©ration GPU")
        recommended_device = "cuda"
    else:
        print("   ‚ö†Ô∏è  Utilisation CPU uniquement")
        print("   üí° Optimiser avec tous les c≈ìurs")
        recommended_device = "cpu"
    
    # Configuration optimale
    print(f"\n‚öôÔ∏è  Configuration optimale:")
    print(f"   - Device recommand√©: {recommended_device}")
    print(f"   - Threads CPU: {psutil.cpu_count()}")
    print(f"   - Batch size: 32 (optimis√© pour M4)")
    print(f"   - Mixed precision: {'Activ√©' if recommended_device != 'cpu' else 'Non applicable'}")
    
    return recommended_device

def test_performance():
    """Teste les performances sur diff√©rents devices."""
    print(f"\nüìä Test de performances:")
    print("-" * 30)
    
    import time
    
    # Test CPU
    device_cpu = torch.device("cpu")
    x_cpu = torch.randn(1000, 1000)
    y_cpu = torch.randn(1000, 1000)
    
    start = time.time()
    z_cpu = torch.mm(x_cpu, y_cpu)
    cpu_time = time.time() - start
    print(f"   CPU: {cpu_time:.3f}s")
    
    # Test MPS si disponible
    if torch.backends.mps.is_available():
        device_mps = torch.device("mps")
        x_mps = x_cpu.to(device_mps)
        y_mps = y_cpu.to(device_mps)
        
        # Warmup
        torch.mm(x_mps, y_mps)
        
        start = time.time()
        z_mps = torch.mm(x_mps, y_mps)
        mps_time = time.time() - start
        speedup = cpu_time / mps_time
        print(f"   MPS: {mps_time:.3f}s (x{speedup:.1f} plus rapide)")
    
    # Test CUDA si disponible
    if torch.cuda.is_available():
        device_cuda = torch.device("cuda")
        x_cuda = x_cpu.to(device_cuda)
        y_cuda = y_cpu.to(device_cuda)
        
        # Warmup
        torch.mm(x_cuda, y_cuda)
        
        start = time.time()
        z_cuda = torch.mm(x_cuda, y_cuda)
        cuda_time = time.time() - start
        speedup = cpu_time / cuda_time
        print(f"   CUDA: {cuda_time:.3f}s (x{speedup:.1f} plus rapide)")

def generate_config():
    """G√©n√®re un fichier de configuration optimis√©."""
    print(f"\n‚öôÔ∏è  G√©n√©ration de la configuration optimis√©e...")
    
    device = detect_m4_capabilities()
    
    config = f"""# Configuration optimis√©e pour Mac M4
# G√©n√©r√©e automatiquement par detect_m4_capabilities.py

# Device optimal
OPTIMAL_DEVICE = "{device}"

# Optimisations CPU
CPU_THREADS = {psutil.cpu_count()}

# Optimisations GPU/MPS
USE_MPS = {torch.backends.mps.is_available()}
USE_CUDA = {torch.cuda.is_available()}

# Param√®tres optimis√©s
BATCH_SIZE = 32
MIXED_PRECISION = {device != 'cpu'}

# Configuration PyTorch
TORCH_SETTINGS = {{
    'num_threads': {psutil.cpu_count()},
    'mps_enabled': {torch.backends.mps.is_available()},
    'cuda_enabled': {torch.cuda.is_available()}
}}
"""
    
    with open('m4_config.py', 'w') as f:
        f.write(config)
    
    print("‚úÖ Configuration sauvegard√©e dans m4_config.py")

def main():
    """Fonction principale."""
    try:
        # D√©tection des capacit√©s
        device = detect_m4_capabilities()
        
        # Test de performances
        test_performance()
        
        # G√©n√©ration de la configuration
        generate_config()
        
        print(f"\nüéâ D√©tection termin√©e!")
        print(f"üí° Device recommand√© pour RAG: {device}")
        
        if device == "mps":
            print(f"üöÄ Votre Mac M4 est optimis√© pour l'IA!")
            print(f"üìà Attendez-vous √† des gains de performance significatifs")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la d√©tection: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
