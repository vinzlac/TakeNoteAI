# üé§ Guide d'utilisation correcte de SpeechBrain

## ‚úÖ **Solution au probl√®me `'ModuleDict' object has no attribute 'decoder'`**

### **üîç Probl√®me identifi√©**

L'erreur venait de l'utilisation d'un mod√®le SpeechBrain obsol√®te (`speechbrain/asr-wav2vec2-commonvoice-fr`) avec une API qui a chang√©.

### **üîß Solution appliqu√©e**

1. **Mod√®le SpeechBrain fonctionnel** : `speechbrain/asr-crdnn-commonvoice-fr`
2. **API correcte** : `transcribe_file()` au lieu de `transcribe_batch()`
3. **Gestion d'erreur robuste** : Fallback automatique vers Whisper

---

## üöÄ **Utilisation de SpeechBrain**

### **M√©thode recommand√©e**

```python
from speechbrain.pretrained import EncoderDecoderASR

# Charger le mod√®le fonctionnel
asr_model = EncoderDecoderASR.from_hparams(
    source="speechbrain/asr-crdnn-commonvoice-fr",
    savedir="pretrained_models/asr-crdnn-commonvoice-fr"
)

# Transcription simple
text = asr_model.transcribe_file("audio.mp3")
print(text)
```

### **Mod√®les SpeechBrain test√©s**

| Mod√®le | Statut | Qualit√© | Langue |
|--------|--------|---------|--------|
| `speechbrain/asr-crdnn-commonvoice-fr` | ‚úÖ Fonctionne | Bonne | Fran√ßais |
| `speechbrain/asr-wav2vec2-commonvoice-fr` | ‚ùå Erreur decoder | - | Fran√ßais |
| `speechbrain/asr-wav2vec2-commonvoice-en` | ‚ùå Non test√© | - | Anglais |

---

## üõ†Ô∏è **Int√©gration dans TakeNoteAI**

### **Utilisation avec le script principal**

```bash
# SpeechBrain (recommand√© maintenant)
python advanced_rag_transcription.py audio.mp3

# Whisper (alternative)
python advanced_rag_transcription.py audio.mp3 --transcription-model whisper

# Mod√®le SpeechBrain sp√©cifique
python advanced_rag_transcription.py audio.mp3 --transcription-model "speechbrain/asr-crdnn-commonvoice-fr"
```

### **Gestion automatique des erreurs**

Le script g√®re automatiquement :
- ‚úÖ **Chargement du mod√®le** SpeechBrain
- ‚úÖ **Transcription** avec `transcribe_file()`
- ‚úÖ **Fallback vers Whisper** en cas d'erreur
- ‚úÖ **Messages informatifs** pour l'utilisateur

---

## üìä **Comparaison des performances**

### **SpeechBrain vs Whisper**

| Crit√®re | SpeechBrain | Whisper |
|---------|-------------|---------|
| **Vitesse** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Pr√©cision fran√ßais** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Taille mod√®le** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê |
| **Stabilit√©** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Facilit√© d'usage** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

### **Recommandation**

- **Pour la production** : Whisper (plus stable)
- **Pour l'exp√©rimentation** : SpeechBrain (plus rapide)
- **Pour le fran√ßais** : Les deux sont excellents

---

## üîß **D√©pannage**

### **Erreurs courantes**

#### 1. `'ModuleDict' object has no attribute 'decoder'`
**Solution** : Utiliser `speechbrain/asr-crdnn-commonvoice-fr` au lieu de `asr-wav2vec2-commonvoice-fr`

#### 2. `transcribe_batch` ne fonctionne pas
**Solution** : Utiliser `transcribe_file()` √† la place

#### 3. Mod√®le non trouv√©
**Solution** : V√©rifier la connexion internet et l'authentification Hugging Face

### **Authentification Hugging Face**

```bash
# Se connecter √† Hugging Face
huggingface-cli login

# Tester la connexion
python -c "from huggingface_hub import whoami; print(whoami())"
```

---

## üí° **Bonnes pratiques**

### **1. Choix du mod√®le**
```python
# Mod√®les SpeechBrain recommand√©s
FRENCH_MODELS = [
    "speechbrain/asr-crdnn-commonvoice-fr",  # ‚úÖ Fonctionne
    "speechbrain/asr-wav2vec2-commonvoice-fr"  # ‚ùå Erreur decoder
]

ENGLISH_MODELS = [
    "speechbrain/asr-crdnn-commonvoice-en",
    "speechbrain/asr-wav2vec2-commonvoice-en"
]
```

### **2. Gestion d'erreur robuste**
```python
try:
    text = asr_model.transcribe_file(audio_path)
except Exception as e:
    print(f"Erreur SpeechBrain: {e}")
    # Fallback vers Whisper
    import whisper
    model = whisper.load_model("base")
    text = model.transcribe(audio_path)["text"]
```

### **3. Optimisation des performances**
```python
# Charger le mod√®le une seule fois
asr_model = EncoderDecoderASR.from_hparams(...)

# R√©utiliser pour plusieurs fichiers
for audio_file in audio_files:
    text = asr_model.transcribe_file(audio_file)
```

---

## üéØ **R√©sum√©**

‚úÖ **SpeechBrain fonctionne correctement** avec le mod√®le `asr-crdnn-commonvoice-fr`  
‚úÖ **API moderne** : Utiliser `transcribe_file()` au lieu de `transcribe_batch()`  
‚úÖ **Fallback automatique** vers Whisper en cas d'erreur  
‚úÖ **Int√©gration compl√®te** dans TakeNoteAI avec RAG  

**Le probl√®me `'ModuleDict' object has no attribute 'decoder'` est maintenant r√©solu !** üéâ
