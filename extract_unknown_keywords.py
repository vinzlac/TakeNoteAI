#!/usr/bin/env python3
"""
Script pour extraire les mots-cl√©s inconnus/techniques d'une transcription
Identifie les termes qui pourraient n√©cessiter d'√™tre ajout√©s aux mots-cl√©s personnalis√©s
"""

import json
import re
import argparse
from pathlib import Path
from collections import Counter
from typing import List, Dict, Set
import spacy

class UnknownKeywordExtractor:
    """Extracteur de mots-cl√©s inconnus/techniques."""
    
    def __init__(self):
        """Initialise l'extracteur."""
        print("üîß Initialisation de l'extracteur de mots-cl√©s...")
        
        # Charger le mod√®le spaCy fran√ßais si disponible
        try:
            self.nlp = spacy.load("fr_core_news_sm")
            print("‚úÖ Mod√®le spaCy fran√ßais charg√©")
        except OSError:
            print("‚ö†Ô∏è  Mod√®le spaCy non trouv√©, utilisation de filtres basiques")
            self.nlp = None
        
        # Mots fran√ßais courants √† exclure
        self.common_french_words = {
            "le", "la", "les", "de", "du", "des", "un", "une", "et", "ou", "mais", "donc", "car",
            "je", "tu", "il", "elle", "nous", "vous", "ils", "elles", "ce", "cette", "ces",
            "qui", "que", "quoi", "o√π", "quand", "comment", "pourquoi", "est", "sont", "√™tre",
            "avoir", "faire", "aller", "venir", "voir", "dire", "savoir", "pouvoir", "vouloir",
            "avec", "sans", "pour", "dans", "sur", "sous", "par", "vers", "entre", "chez",
            "tr√®s", "plus", "moins", "bien", "mal", "bon", "mauvais", "grand", "petit",
            "nouveau", "ancien", "premier", "dernier", "autre", "m√™me", "tout", "tous",
            "son", "sa", "ses", "mon", "ma", "mes", "ton", "ta", "tes", "notre", "nos",
            "votre", "vos", "leur", "leurs", "celui", "celle", "ceux", "celles"
        }
        
        # Acronymes techniques connus
        self.known_acronyms = {
            "API", "URL", "HTTP", "HTTPS", "SQL", "XML", "JSON", "PDF", "CSV", "HTML",
            "CSS", "JS", "JSX", "TS", "TSX", "PHP", "ASP", "JSP", "REST", "SOAP",
            "OAuth", "JWT", "SSL", "TLS", "DNS", "IP", "TCP", "UDP", "FTP", "SFTP",
            "SSH", "VPN", "LDAP", "AD", "SAML", "OIDC", "GDPR", "RGPD", "GDPR",
            "GDPR", "ISO", "IEEE", "ANSI", "ASCII", "UTF", "Unicode", "ASCII",
            "CPU", "RAM", "ROM", "SSD", "HDD", "GPU", "USB", "HDMI", "VGA", "DVI",
            "CD", "DVD", "BD", "MP3", "MP4", "AVI", "MOV", "WMV", "FLV", "MKV",
            "JPEG", "JPG", "PNG", "GIF", "SVG", "BMP", "TIFF", "RAW", "PSD", "AI",
            "EPS", "PDF", "DOC", "DOCX", "XLS", "XLSX", "PPT", "PPTX", "TXT", "RTF"
        }
        
        # Mots techniques connus
        self.known_technical_terms = {
            "application", "syst√®me", "d√©veloppement", "architecture", "code", "programme",
            "logiciel", "mat√©riel", "r√©seau", "serveur", "client", "base", "donn√©es",
            "base de donn√©es", "interface", "utilisateur", "admin", "administrateur",
            "configuration", "param√®tre", "variable", "fonction", "m√©thode", "classe",
            "objet", "h√©ritage", "polymorphisme", "encapsulation", "abstraction",
            "algorithme", "structure", "donn√©es", "table", "champ", "enregistrement",
            "requ√™te", "insertion", "mise √† jour", "suppression", "s√©lection", "jointure",
            "index", "contrainte", "cl√© primaire", "cl√© √©trang√®re", "trigger", "proc√©dure",
            "stock√©e", "vue", "transaction", "commit", "rollback", "backup", "restore",
            "migration", "d√©ploiement", "environnement", "production", "test", "d√©veloppement",
            "staging", "int√©gration", "continue", "d√©livrance", "continue", "pipeline",
            "build", "release", "version", "branche", "merge", "pull", "request",
            "commit", "push", "clone", "fork", "repository", "repository", "git",
            "github", "gitlab", "bitbucket", "jenkins", "docker", "kubernetes",
            "microservice", "service", "orchestration", "container", "image",
            "registry", "deployment", "scaling", "load", "balancing", "monitoring",
            "logging", "metrics", "alerting", "dashboard", "grafana", "prometheus",
            "elk", "stack", "elasticsearch", "logstash", "kibana", "fluentd",
            "redis", "memcached", "rabbitmq", "kafka", "mongodb", "postgresql",
            "mysql", "oracle", "sqlite", "cassandra", "neo4j", "influxdb"
        }
        
        print("‚úÖ Extracteur initialis√©")
    
    def extract_unknown_keywords(self, text: str, min_length: int = 2, max_length: int = 20) -> List[Dict]:
        """
        Extrait les mots-cl√©s potentiellement inconnus/techniques du texte.
        
        Args:
            text (str): Texte √† analyser
            min_length (int): Longueur minimale des mots
            max_length (int): Longueur maximale des mots
            
        Returns:
            List[Dict]: Liste des mots-cl√©s avec m√©tadonn√©es
        """
        print("üîç Extraction des mots-cl√©s inconnus...")
        
        # Nettoyer le texte
        cleaned_text = self._clean_text(text)
        
        # Extraire les mots
        words = self._extract_words(cleaned_text, min_length, max_length)
        
        # Analyser chaque mot
        unknown_keywords = []
        
        for word, count in words.most_common():
            if self._is_potential_unknown_keyword(word):
                confidence = self._calculate_confidence(word, count, len(words))
                
                unknown_keywords.append({
                    "word": word,
                    "count": count,
                    "confidence": confidence,
                    "category": self._categorize_word(word),
                    "examples": self._find_examples(word, text)
                })
        
        # Trier par confiance d√©croissante
        unknown_keywords.sort(key=lambda x: x["confidence"], reverse=True)
        
        print(f"‚úÖ {len(unknown_keywords)} mots-cl√©s potentiels trouv√©s")
        return unknown_keywords
    
    def _clean_text(self, text: str) -> str:
        """Nettoie le texte pour l'analyse."""
        # Supprimer la ponctuation excessive
        text = re.sub(r'[^\w\s\-\.]', ' ', text)
        
        # Supprimer les espaces multiples
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def _extract_words(self, text: str, min_length: int, max_length: int) -> Counter:
        """Extrait et compte les mots du texte."""
        words = []
        
        # Diviser en mots
        tokens = text.split()
        
        for token in tokens:
            # Nettoyer le token
            word = token.strip().lower()
            
            # Filtrer par longueur
            if min_length <= len(word) <= max_length:
                # V√©rifier que ce n'est pas un nombre pur
                if not word.isdigit():
                    words.append(word)
        
        return Counter(words)
    
    def _is_potential_unknown_keyword(self, word: str) -> bool:
        """D√©termine si un mot est potentiellement un mot-cl√© inconnu."""
        # Exclure les mots fran√ßais courants
        if word in self.common_french_words:
            return False
        
        # Exclure les acronymes connus
        if word.upper() in self.known_acronyms:
            return False
        
        # Exclure les termes techniques connus
        if word in self.known_technical_terms:
            return False
        
        # Crit√®res pour les mots-cl√©s potentiels
        
        # 1. Acronymes (tout en majuscules, 2-6 caract√®res)
        if re.match(r'^[A-Z]{2,6}$', word):
            return True
        
        # 2. Mots avec majuscules au milieu (CamelCase)
        if re.search(r'[A-Z][a-z]+[A-Z]', word):
            return True
        
        # 3. Mots avec chiffres
        if re.search(r'\d', word):
            return True
        
        # 4. Mots tr√®s courts (2-3 caract√®res) qui ne sont pas des mots courants
        if len(word) <= 3 and word not in {"oui", "non", "ok", "pas", "que", "qui", "le", "la", "de", "du", "un", "et"}:
            return True
        
        # 5. Mots avec tirets
        if '-' in word:
            return True
        
        # 6. Mots avec underscores
        if '_' in word:
            return True
        
        # 7. Noms propres potentiels (commen√ßant par majuscule, 3+ caract√®res)
        if word[0].isupper() and len(word) >= 3:
            return True
        
        # 8. Mots techniques (finissant par des suffixes techniques)
        technical_suffixes = ['ing', 'tion', 'sion', 'ment', 'age', 'isme', 'iste', 'eur', 'euse']
        if any(word.endswith(suffix) for suffix in technical_suffixes):
            return True
        
        # 9. Mots compos√©s avec majuscules (comme "go-live", "code-review")
        if '-' in word and any(c.isupper() for c in word):
            return True
        
        # 10. Mots avec des patterns techniques (comme "v1", "v2", "api", etc.)
        if re.match(r'^v\d+$', word.lower()) or re.match(r'^[a-z]+\d+$', word.lower()):
            return True
        
        return False
    
    def _calculate_confidence(self, word: str, count: int, total_words: int) -> float:
        """Calcule la confiance qu'un mot soit un mot-cl√© inconnu."""
        confidence = 0.0
        
        # Fr√©quence relative
        frequency = count / total_words
        if frequency > 0.001:  # Plus de 0.1% du texte
            confidence += 0.3
        
        # Type de mot
        if re.match(r'^[A-Z]{2,6}$', word):  # Acronyme
            confidence += 0.4
        elif re.search(r'[A-Z][a-z]+[A-Z]', word):  # CamelCase
            confidence += 0.3
        elif re.search(r'\d', word):  # Contient des chiffres
            confidence += 0.2
        elif len(word) <= 3:  # Court
            confidence += 0.1
        elif '-' in word or '_' in word:  # Avec tirets/underscores
            confidence += 0.2
        elif word[0].isupper():  # Commence par majuscule
            confidence += 0.1
        
        # Limiter √† 1.0
        return min(confidence, 1.0)
    
    def _categorize_word(self, word: str) -> str:
        """Cat√©gorise un mot-cl√©."""
        if re.match(r'^[A-Z]{2,6}$', word):
            return "Acronyme"
        elif re.search(r'[A-Z][a-z]+[A-Z]', word):
            return "CamelCase"
        elif re.search(r'\d', word):
            return "Avec chiffres"
        elif len(word) <= 3:
            return "Court"
        elif '-' in word or '_' in word:
            return "Compos√©"
        elif word[0].isupper():
            return "Nom propre"
        else:
            return "Technique"
    
    def _find_examples(self, word: str, text: str, max_examples: int = 3) -> List[str]:
        """Trouve des exemples d'utilisation du mot dans le texte."""
        examples = []
        sentences = text.split('.')
        
        for sentence in sentences:
            if word.lower() in sentence.lower() and len(examples) < max_examples:
                # Nettoyer la phrase
                clean_sentence = sentence.strip()
                if len(clean_sentence) > 10:  # √âviter les phrases trop courtes
                    examples.append(clean_sentence)
        
        return examples
    
    def save_results(self, unknown_keywords: List[Dict], output_file: str):
        """Sauvegarde les r√©sultats dans un fichier."""
        results = {
            "total_keywords": len(unknown_keywords),
            "keywords": unknown_keywords,
            "summary": {
                "acronyms": len([k for k in unknown_keywords if k["category"] == "Acronyme"]),
                "camel_case": len([k for k in unknown_keywords if k["category"] == "CamelCase"]),
                "with_numbers": len([k for k in unknown_keywords if k["category"] == "Avec chiffres"]),
                "short": len([k for k in unknown_keywords if k["category"] == "Court"]),
                "composed": len([k for k in unknown_keywords if k["category"] == "Compos√©"]),
                "proper_nouns": len([k for k in unknown_keywords if k["category"] == "Nom propre"]),
                "technical": len([k for k in unknown_keywords if k["category"] == "Technique"])
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ R√©sultats sauvegard√©s: {output_file}")
    
    def print_summary(self, unknown_keywords: List[Dict]):
        """Affiche un r√©sum√© des mots-cl√©s trouv√©s."""
        print(f"\nüìä R√©sum√© des mots-cl√©s inconnus trouv√©s:")
        print(f"   Total: {len(unknown_keywords)}")
        
        # Par cat√©gorie
        categories = {}
        for keyword in unknown_keywords:
            category = keyword["category"]
            if category not in categories:
                categories[category] = 0
            categories[category] += 1
        
        print(f"\nüìã Par cat√©gorie:")
        for category, count in sorted(categories.items()):
            print(f"   - {category}: {count}")
        
        # Top 10
        print(f"\nüèÜ Top 10 des mots-cl√©s les plus probables:")
        for i, keyword in enumerate(unknown_keywords[:10], 1):
            print(f"   {i:2d}. {keyword['word']} ({keyword['category']}) - "
                  f"Confiance: {keyword['confidence']:.2f} - "
                  f"Occurrences: {keyword['count']}")


def main():
    """Fonction principale."""
    parser = argparse.ArgumentParser(
        description="Extrait les mots-cl√©s inconnus/techniques d'une transcription",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  %(prog)s fichier.json                           # Analyser un fichier JSON
  %(prog)s fichier.json --min-length 3            # Mots de 3+ caract√®res
  %(prog)s fichier.json --output mots_cles.json   # Sortie personnalis√©e
  %(prog)s fichier.json --top 20                  # Top 20 seulement
        """
    )
    
    parser.add_argument("input", help="Fichier JSON de transcription √† analyser")
    parser.add_argument("--output", "-o", help="Fichier de sortie (d√©faut: mots_cles_inconnus.json)")
    parser.add_argument("--min-length", type=int, default=2, help="Longueur minimale des mots (d√©faut: 2)")
    parser.add_argument("--max-length", type=int, default=20, help="Longueur maximale des mots (d√©faut: 20)")
    parser.add_argument("--top", type=int, help="Afficher seulement les N premiers r√©sultats")
    parser.add_argument("--save-examples", action="store_true", help="Sauvegarder les exemples d'utilisation")
    
    args = parser.parse_args()
    
    try:
        # V√©rifier le fichier d'entr√©e
        input_file = Path(args.input)
        if not input_file.exists():
            print(f"‚ùå Fichier non trouv√©: {input_file}")
            return 1
        
        # D√©terminer le fichier de sortie
        if args.output:
            output_file = args.output
        else:
            output_file = f"mots_cles_inconnus_{input_file.stem}.json"
        
        print(f"üîç Analyse du fichier: {input_file}")
        print(f"üìÑ Sortie: {output_file}")
        
        # Charger le fichier JSON
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Extraire le texte
        if 'transcription' in data:
            if isinstance(data['transcription'], dict):
                text = data['transcription'].get('text', '')
            else:
                text = str(data['transcription'])
        else:
            print("‚ùå Aucune transcription trouv√©e dans le fichier")
            return 1
        
        if not text:
            print("‚ùå Texte de transcription vide")
            return 1
        
        print(f"üìù Texte analys√©: {len(text)} caract√®res")
        
        # Initialiser l'extracteur
        extractor = UnknownKeywordExtractor()
        
        # Extraire les mots-cl√©s
        unknown_keywords = extractor.extract_unknown_keywords(
            text, 
            min_length=args.min_length,
            max_length=args.max_length
        )
        
        if not unknown_keywords:
            print("‚úÖ Aucun mot-cl√© inconnu d√©tect√©")
            return 0
        
        # Limiter les r√©sultats si demand√©
        if args.top:
            unknown_keywords = unknown_keywords[:args.top]
        
        # Supprimer les exemples si non demand√©s
        if not args.save_examples:
            for keyword in unknown_keywords:
                keyword.pop('examples', None)
        
        # Afficher le r√©sum√©
        extractor.print_summary(unknown_keywords)
        
        # Sauvegarder les r√©sultats
        extractor.save_results(unknown_keywords, output_file)
        
        # Afficher quelques exemples
        print(f"\nüí° Exemples de mots-cl√©s trouv√©s:")
        for keyword in unknown_keywords[:5]:
            print(f"   - '{keyword['word']}' ({keyword['category']}) - "
                  f"Confiance: {keyword['confidence']:.2f}")
            if args.save_examples and keyword.get('examples'):
                print(f"     Exemple: '{keyword['examples'][0][:60]}...'")
        
        print(f"\nüéØ Recommandations:")
        print(f"   1. V√©rifiez les mots-cl√©s avec une confiance > 0.5")
        print(f"   2. Ajoutez les acronymes et noms propres √† votre liste")
        print(f"   3. Utilisez: python advanced_rag_transcription_with_keywords.py --keywords \"mot1,mot2,mot3\"")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
