#!/usr/bin/env python3
"""
Script pour g√©n√©rer automatiquement un fichier de mots-cl√©s
√† partir d'une transcription audio
"""

import warnings
import torch
import os

# Optimisations M4 pour l'analyse
if torch.backends.mps.is_available():
    torch.set_num_threads(14)
    os.environ['OMP_NUM_THREADS'] = '14'
    os.environ['MKL_NUM_THREADS'] = '14'
    os.environ['NUMEXPR_NUM_THREADS'] = '14'
import json
import re
import argparse
from pathlib import Path
from collections import Counter
from typing import List, Dict, Set

# Import du gestionnaire de sortie
try:
    from output_manager import OutputManager
    OUTPUT_MANAGER = OutputManager()
except ImportError:
    print("‚ö†Ô∏è  output_manager.py non trouv√©, utilisation des chemins par d√©faut")
    OUTPUT_MANAGER = None

class KeywordGenerator:
    """G√©n√©rateur de mots-cl√©s √† partir de transcriptions."""
    
    def __init__(self):
        """Initialise le g√©n√©rateur."""
        print("üîß Initialisation du g√©n√©rateur de mots-cl√©s...")
        
        # Mots fran√ßais courants √† exclure (avec variantes majuscules)
        self.common_french_words = {
            # Articles et d√©terminants
            "le", "la", "les", "de", "du", "des", "un", "une", "et", "ou", "mais", "donc", "car",
            "Le", "La", "Les", "De", "Du", "Des", "Un", "Une", "Et", "Ou", "Mais", "Donc", "Car",
            
            # Pronoms
            "je", "tu", "il", "elle", "nous", "vous", "ils", "elles", "ce", "cette", "ces",
            "Je", "Tu", "Il", "Elle", "Nous", "Vous", "Ils", "Elles", "Ce", "Cette", "Ces",
            
            # Mots interrogatifs
            "qui", "que", "quoi", "o√π", "quand", "comment", "pourquoi", "est-ce", "qu'est-ce",
            "Qui", "Que", "Quoi", "O√π", "Quand", "Comment", "Pourquoi", "Est-ce", "Qu'est-ce",
            
            # Verbes courants
            "est", "sont", "√™tre", "avoir", "faire", "aller", "venir", "voir", "dire", "savoir", "pouvoir", "vouloir",
            "Est", "Sont", "√ätre", "Avoir", "Faire", "Aller", "Venir", "Voir", "Dire", "Savoir", "Pouvoir", "Vouloir",
            
            # Pr√©positions et conjonctions
            "avec", "sans", "pour", "dans", "sur", "sous", "par", "vers", "entre", "chez", "apr√®s", "avant", "pendant",
            "Avec", "Sans", "Pour", "Dans", "Sur", "Sous", "Par", "Vers", "Entre", "Chez", "Apr√®s", "Avant", "Pendant",
            
            # Adverbes
            "tr√®s", "plus", "moins", "bien", "mal", "bon", "mauvais", "grand", "petit", "maintenant", "toujours", "jamais",
            "Tr√®s", "Plus", "Moins", "Bien", "Mal", "Bon", "Mauvais", "Grand", "Petit", "Maintenant", "Toujours", "Jamais",
            
            # Mots de liaison
            "donc", "alors", "puis", "ensuite", "enfin", "parce", "parce que", "puisque", "comme", "si", "quand",
            "Donc", "Alors", "Puis", "Ensuite", "Enfin", "Parce", "Parce que", "Puisque", "Comme", "Si", "Quand",
            
            # Mots de politesse
            "merci", "pardon", "excuse", "bonjour", "bonsoir", "salut", "au revoir",
            "Merci", "Pardon", "Excuse", "Bonjour", "Bonsoir", "Salut", "Au revoir",
            
            # Mots courants
            "oui", "non", "ok", "pas", "que", "qui", "comme", "si", "alors", "donc", "peut", "√™tre",
            "Oui", "Non", "Ok", "Pas", "Que", "Qui", "Comme", "Si", "Alors", "Donc", "Peut", "√ätre",
            
            # Expressions courantes
            "voil√†", "voici", "c'est", "il y a", "√ßa va", "c'est √ßa", "c'est bon", "c'est bien",
            "Voil√†", "Voici", "C'est", "Il y a", "√áa va", "C'est √ßa", "C'est bon", "C'est bien",
            
            # Mots techniques g√©n√©riques (√† exclure car trop g√©n√©raux)
            "syst√®me", "application", "projet", "√©quipe", "travail", "fonction", "r√¥le", "mission",
            "Syst√®me", "Application", "Projet", "√âquipe", "Travail", "Fonction", "R√¥le", "Mission"
        }
        
        print("‚úÖ G√©n√©rateur initialis√©")
    
    def extract_keywords_from_transcription(self, text: str) -> List[str]:
        """
        Extrait les mots-cl√©s d'une transcription.
        
        Args:
            text (str): Texte de la transcription
            
        Returns:
            List[str]: Liste des mots-cl√©s extraits
        """
        print("üîç Extraction des mots-cl√©s de la transcription...")
        
        # Nettoyer le texte
        cleaned_text = self._clean_text(text)
        
        # Extraire les mots-cl√©s potentiels
        keywords = []
        
        # 1. Acronymes (2-6 caract√®res en majuscules)
        acronyms = re.findall(r'\b[A-Z]{2,6}\b', cleaned_text)
        keywords.extend(acronyms)
        
        # 2. Noms propres (commen√ßant par majuscule, 3+ caract√®res)
        proper_nouns = re.findall(r'\b[A-Z][a-z]{2,}\b', cleaned_text)
        # Filtrer les mots fran√ßais courants
        proper_nouns = [noun for noun in proper_nouns if noun not in {
            "Le", "La", "Les", "De", "Du", "Des", "Un", "Une", "Et", "Ou", "Mais", 
            "Donc", "Car", "Pour", "Dans", "Sur", "Sous", "Par", "Vers", "Entre",
            "Avec", "Sans", "Avec", "Dans", "Pour", "Sur", "Sous", "Par", "Vers",
            "Tr√®s", "Plus", "Moins", "Bien", "Mal", "Bon", "Mauvais", "Grand", "Petit",
            "Nouveau", "Ancien", "Premier", "Dernier", "Autre", "M√™me", "Tout", "Tous",
            "Maintenant", "Toujours", "Jamais", "Souvent", "Parfois", "Rarement",
            "Beaucoup", "Peu", "Assez", "Trop", "Autant", "Tant", "Ici", "L√†", "Partout",
            "Ailleurs", "Dedans", "Dehors", "Dessus", "Dessous", "Devant", "Derri√®re",
            "Haut", "Bas", "Droite", "Gauche", "Milieu", "Centre", "Bord", "C√¥t√©",
            "Partie", "Endroit", "Lieu", "Place", "Position", "Situation", "√âtat",
            "Condition", "Mani√®re", "Fa√ßon", "Moyen", "M√©thode", "Technique", "Syst√®me",
            "Proc√©d√©", "Processus", "Op√©ration", "Action", "Activit√©", "Travail",
            "Fonction", "R√¥le", "Mission", "T√¢che", "Objectif", "But", "R√©sultat",
            "Effet", "Cons√©quence", "Impact", "Influence", "Importance", "Valeur",
            "Prix", "Co√ªt", "Budget", "Finance", "Argent", "Monnaie", "Temps",
            "Moment", "Instant", "P√©riode", "Dur√©e", "Longueur", "Largeur", "Hauteur",
            "Profondeur", "Taille", "Dimension", "Mesure", "Quantit√©", "Nombre",
            "Chiffre", "Pourcentage", "Ratio", "Proportion", "Fraction", "Total",
            "Somme", "Moyenne", "Maximum", "Minimum", "Limite", "Apr√®s", "Avant",
            "Pendant", "Depuis", "Jusque", "Vers", "Contre", "Selon", "Malgr√©",
            "Gr√¢ce", "Faute", "Cause", "Suite", "R√©sultat", "Cons√©quence", "Effet",
            "Impact", "Influence", "Changement", "Modification", "Am√©lioration",
            "D√©gradation", "√âvolution", "Progr√®s", "R√©gression", "Augmentation",
            "Diminution", "Croissance", "D√©croissance", "Stabilit√©", "Variation",
            "Fluctuation", "Oscillation", "Tendance", "Orientation", "Direction",
            "Sens", "C√¥t√©", "Partie", "Section", "Zone", "R√©gion", "Territoire",
            "Domaine", "Secteur", "Branche", "Sp√©cialit√©", "Comp√©tence", "Connaissance",
            "Savoir", "Exp√©rience", "Pratique", "Th√©orie", "Concept", "Id√©e", "Notion",
            "Principe", "R√®gle", "Loi", "Norme", "Standard", "Crit√®re", "Condition",
            "Exigence", "Besoin", "Demande", "Requ√™te", "Proposition", "Suggestion",
            "Recommandation", "Conseil", "Avis", "Opinion", "Jugement", "√âvaluation",
            "Appr√©ciation", "Estimation", "Calcul", "Comptage", "D√©nombrement",
            "Inventaire", "Liste", "Catalogue", "R√©pertoire", "Annuaire", "Index",
            "Table", "Tableau", "Graphique", "Diagramme", "Sch√©ma", "Plan", "Carte",
            "Croquis", "Dessin", "Image", "Photo", "Illustration", "Figure", "Exemple",
            "Cas", "Situation", "Contexte", "Environnement", "Cadre", "Structure",
            "Organisation", "Arrangement", "Disposition", "Configuration", "Param√®tre",
            "R√©glage", "Ajustement", "Adaptation", "Modification", "Transformation",
            "Changement", "√âvolution", "D√©veloppement", "Croissance", "Expansion",
            "Extension", "Augmentation", "Agrandissement", "√âlargissement",
            "Approfondissement", "Enrichissement", "Am√©lioration", "Perfectionnement",
            "Optimisation", "Maximisation", "Minimisation", "R√©duction", "Diminution",
            "Compression", "Condensation", "Concentration", "Centralisation",
            "D√©centralisation", "Distribution", "R√©partition", "Partage", "Division",
            "S√©paration", "D√©coupage", "Fragmentation", "D√©composition", "Analyse",
            "Synth√®se", "Combinaison", "Association", "Liaison", "Connexion", "Relation",
            "Lien", "Rapport", "Correspondance", "√âquivalence", "Similarit√©",
            "Ressemblance", "Diff√©rence", "Distinction", "Opposition", "Contraste",
            "Comparaison", "Conflit", "Tension", "Harmonie", "√âquilibre", "Stabilit√©",
            "Instabilit√©", "Variabilit√©", "Pr√©visibilit√©", "Impr√©visibilit√©",
            "Certitude", "Incertitude", "Doute", "Confiance", "M√©fiance", "S√©curit√©",
            "Ins√©curit√©", "Protection", "Vuln√©rabilit√©", "Risque", "Danger", "Menace",
            "Opportunit√©", "Chance"
        }]
        keywords.extend(proper_nouns)
        
        # 3. Versions (v1, v2, etc.)
        versions = re.findall(r'\bv\d+\b', cleaned_text.lower())
        keywords.extend([v.upper() for v in versions])
        
        # 4. Mots avec chiffres
        words_with_numbers = re.findall(r'\b[a-zA-Z]+\d+[a-zA-Z]*\b', cleaned_text)
        keywords.extend(words_with_numbers)
        
        # 5. Mots compos√©s avec tirets (go-live, code-review, etc.)
        compound_words = re.findall(r'\b[a-zA-Z]+-[a-zA-Z]+\b', cleaned_text)
        keywords.extend(compound_words)
        
        # 6. CamelCase
        camel_case = re.findall(r'\b[A-Z][a-z]+[A-Z][a-z]*\b', cleaned_text)
        keywords.extend(camel_case)
        
        # D√©dupliquer et filtrer
        unique_keywords = list(set(keywords))
        filtered_keywords = [kw for kw in unique_keywords if self._is_valid_keyword(kw)]
        
        # Trier par fr√©quence d'apparition
        keyword_counts = Counter([kw for kw in keywords if kw in filtered_keywords])
        sorted_keywords = sorted(filtered_keywords, key=lambda x: keyword_counts[x], reverse=True)
        
        print(f"‚úÖ {len(sorted_keywords)} mots-cl√©s extraits")
        return sorted_keywords
    
    def _clean_text(self, text: str) -> str:
        """Nettoie le texte pour l'analyse."""
        # Garder la casse originale
        text = re.sub(r'[^\w\s\-\.]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def _is_valid_keyword(self, word: str) -> bool:
        """V√©rifie si un mot est un mot-cl√© valide."""
        # Exclure les mots fran√ßais courants (avec casse originale)
        if word in self.common_french_words:
            return False
        
        # Exclure les mots fran√ßais courants (en minuscules)
        word_lower = word.lower()
        if word_lower in self.common_french_words:
            return False
        
        # Exclure les mots trop courts (sauf acronymes)
        if len(word) < 2:
            return False
        
        # Exclure les mots trop longs
        if len(word) > 20:
            return False
        
        # Exclure les mots avec trop de caract√®res sp√©ciaux
        if len(re.findall(r'[^a-zA-Z0-9\-]', word)) > len(word) / 2:
            return False
        
        # Exclure les mots qui sont probablement des erreurs de transcription
        # (mots tr√®s courts qui ne sont pas des acronymes)
        if len(word) <= 3 and not re.match(r'^[A-Z]{2,3}$', word):
            # Exclure les pronoms et mots courants courts
            short_common_words = {"moi", "toi", "lui", "elle", "nous", "vous", "eux", "soi"}
            if word_lower in short_common_words:
                return False
        
        # Exclure les mots qui ressemblent √† des erreurs de transcription
        # (mots avec des patterns √©tranges)
        if re.search(r'[aeiou]{3,}', word_lower):  # Trop de voyelles cons√©cutives
            return False
        
        if re.search(r'[bcdfghjklmnpqrstvwxyz]{4,}', word_lower):  # Trop de consonnes cons√©cutives
            return False
        
        return True
    
    def generate_keywords_file(self, keywords: List[str], output_file: str):
        """G√©n√®re un fichier de mots-cl√©s."""
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# Mots-cl√©s g√©n√©r√©s automatiquement √† partir de la transcription\n")
            f.write("# Utilisez ce fichier avec: --keywords-file\n\n")
            
            for keyword in keywords:
                f.write(f"{keyword}\n")
        
        print(f"‚úÖ Fichier de mots-cl√©s g√©n√©r√©: {output_file}")
    
    def print_summary(self, keywords: List[str]):
        """Affiche un r√©sum√© des mots-cl√©s g√©n√©r√©s."""
        print(f"\nüìä R√©sum√© des mots-cl√©s g√©n√©r√©s:")
        print(f"   Total: {len(keywords)}")
        
        # Par cat√©gorie
        acronyms = [kw for kw in keywords if re.match(r'^[A-Z]{2,6}$', kw)]
        proper_nouns = [kw for kw in keywords if kw[0].isupper() and len(kw) > 3]
        versions = [kw for kw in keywords if re.match(r'^V\d+$', kw)]
        compound_words = [kw for kw in keywords if '-' in kw]
        camel_case = [kw for kw in keywords if re.search(r'[A-Z][a-z]+[A-Z]', kw)]
        
        print(f"\nüìã Par cat√©gorie:")
        print(f"   - Acronymes: {len(acronyms)}")
        print(f"   - Noms propres: {len(proper_nouns)}")
        print(f"   - Versions: {len(versions)}")
        print(f"   - Mots compos√©s: {len(compound_words)}")
        print(f"   - CamelCase: {len(camel_case)}")
        
        # Top 20
        print(f"\nüèÜ Top 20 des mots-cl√©s g√©n√©r√©s:")
        for i, keyword in enumerate(keywords[:20], 1):
            print(f"   {i:2d}. {keyword}")


def main():
    """Fonction principale."""
    parser = argparse.ArgumentParser(
        description="G√©n√®re automatiquement un fichier de mots-cl√©s √† partir d'une transcription",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  %(prog)s fichier.json                           # G√©n√©rer des mots-cl√©s
  %(prog)s fichier.json --output mes_keywords.txt # Sortie personnalis√©e
  %(prog)s fichier.json --top 50                  # Limiter √† 50 mots-cl√©s
        """
    )
    
    parser.add_argument("input", help="Fichier JSON de transcription √† analyser")
    parser.add_argument("--output", "-o", help="Fichier de sortie (d√©faut: keywords_generated.txt)")
    parser.add_argument("--top", type=int, help="Limiter √† N mots-cl√©s")
    
    args = parser.parse_args()
    
    try:
        # V√©rifier le fichier d'entr√©e
        input_file = Path(args.input)
        if not input_file.exists():
            print(f"‚ùå Fichier non trouv√©: {input_file}")
            return 1
        
        # D√©terminer le fichier de sortie
        if args.output:
            output_file = args.output
        else:
            filename = f"keywords_generated_{input_file.stem}.txt"
            if OUTPUT_MANAGER:
                output_file = str(OUTPUT_MANAGER.get_keywords_path(filename))
            else:
                output_file = filename
        
        print(f"üîç Analyse du fichier: {input_file}")
        print(f"üìÑ Sortie: {output_file}")
        
        # Charger le fichier JSON
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Extraire le texte
        if 'transcription' in data:
            if isinstance(data['transcription'], dict):
                text = data['transcription'].get('text', '')
            else:
                text = str(data['transcription'])
        else:
            print("‚ùå Aucune transcription trouv√©e dans le fichier")
            return 1
        
        if not text:
            print("‚ùå Texte de transcription vide")
            return 1
        
        print(f"üìù Texte analys√©: {len(text)} caract√®res")
        
        # Initialiser le g√©n√©rateur
        generator = KeywordGenerator()
        
        # Extraire les mots-cl√©s
        keywords = generator.extract_keywords_from_transcription(text)
        
        if not keywords:
            print("‚úÖ Aucun mot-cl√© d√©tect√©")
            return 0
        
        # Limiter les r√©sultats si demand√©
        if args.top:
            keywords = keywords[:args.top]
        
        # Afficher le r√©sum√©
        generator.print_summary(keywords)
        
        # G√©n√©rer le fichier de mots-cl√©s
        generator.generate_keywords_file(keywords, output_file)
        
        print(f"\nüéØ Utilisation:")
        print(f"   1. V√©rifiez le fichier g√©n√©r√©: {output_file}")
        print(f"   2. Utilisez avec: python advanced_rag_transcription_with_keywords.py audio.mp3 --keywords-file {output_file}")
        print(f"   3. Ou copiez les mots-cl√©s: --keywords \"{', '.join(keywords[:10])}\"")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return 1


if __name__ == "__main__":
    exit(main())
